{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:red\">Imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#imports \n",
    "#from tensorflow import keras\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM,Dense,Input,Bidirectional\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "from scipy import spatial\n",
    "from random import shuffle\n",
    "import pickle\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from scipy import spatial\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:red\">Word Embedding</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "embeddings_size = 300\n",
    "i = 0\n",
    "with open('/Users/mohammad/Documents/Internship-IAI/farsi_testing/cc.fa.300.vec') as f:\n",
    "    for line in f:\n",
    "        if i > 400000:\n",
    "            break\n",
    "        i += 1\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = [float(i) for i in values[1:]]\n",
    "        embeddings_index[word] = coefs\n",
    "embeddings_index['<PAD>'] = [0] * 300\n",
    "embeddings_index['<UNK>'] = [1] * 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim(dataSetI , dataSetII):\n",
    "    return 1 - spatial.distance.cosine(dataSetI, dataSetII)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:red\">Preparing our Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "marks = {'؟', '!', '.', '،'}\n",
    "zamir_1 = {'م' , 'ش', 'ت', 'ه','و','ی'} \n",
    "zamir_3 = {'تان', 'شان', 'مان'}\n",
    "def prepareSent(sent):\n",
    "    sent = sent.split()\n",
    "    sent = [i[:-1] if i[-1] in marks or (i[-1] in zamir_1 and i[:-1] in embeddings_index and i not in embeddings_index) else i for i in sent]\n",
    "    sent = [i[:-3] if i[-3:] in zamir_3 and i[:-3] in embeddings_index and i not in embeddings_index else i for i in sent]\n",
    "    tokenized = []\n",
    "    n = 0\n",
    "    while(n != len(sent)):\n",
    "        if n < len(sent) - 2 and (sent[n] + \"‌\" + sent[n+1] + \"‌\" + sent[n+2]) in embeddings_index:\n",
    "            tokenized.append(sent[n] + \"‌\" + sent[n+1] + \"‌\" + sent[n+2])\n",
    "            n += 2\n",
    "        elif n != len(sent) -1 and (sent[n] + \"‌\" + sent[n+1]) in embeddings_index:\n",
    "            tokenized.append(sent[n] + \"‌\" + sent[n+1])\n",
    "            n += 1\n",
    "        else:\n",
    "            tokenized.append(sent[n])\n",
    "        n += 1\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size = 4\n",
    "X_train = []\n",
    "Y_train = []\n",
    "for i in range(1,class_size+1):\n",
    "    with open('class{}.csv'.format(i)) as f:\n",
    "        reader = csv.reader(f)\n",
    "        class_list = [r[0] for r in reader]\n",
    "        y = [1 if j == i else 0 for j in range(1 , class_size+1)]\n",
    "        class_list = [(o,y) for o in class_list]\n",
    "        X_train = X_train + class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whichClass(inp):\n",
    "    for i in range(len(inp)):\n",
    "        if 1 == inp[i]:\n",
    "            if i == 0:\n",
    "                return \"Address\"\n",
    "            elif i == 1:\n",
    "                return \"Resturant\"\n",
    "            elif i == 2:\n",
    "                return \"Home Service\"\n",
    "            elif i == 3:\n",
    "                return \"Laundary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(X_train)\n",
    "shuffle(X_train)\n",
    "shuffle(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = [i[1] for i in X_train]\n",
    "X_train = [prepareSent(i[0]) for i in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ = 20\n",
    "def wordToVec(data):\n",
    "    for s in range(len(data)):\n",
    "        n = MAX_SEQ - len(data[s])\n",
    "        if n < 0:\n",
    "            data[s] = data[s][:MAX_SEQ]\n",
    "        else:\n",
    "            for i in range(n):\n",
    "                data[s].append('<PAD>')\n",
    "        for v in range(len(data[s])):\n",
    "            if data[s][v] not in embeddings_index:\n",
    "                data[s][v] = embeddings_index['<UNK>']\n",
    "            else:\n",
    "                data[s][v] = embeddings_index[data[s][v]]\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(403, 20, 300)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = wordToVec(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:red\">Building model with Batch size 64</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (16, 20, 300)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (16, 40)                  51360     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (16, 4)                   164       \n",
      "=================================================================\n",
      "Total params: 51,524\n",
      "Trainable params: 51,524\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "input_layer = Input( batch_shape = (BATCH_SIZE, MAX_SEQ, 300))\n",
    "lstm_layer = Bidirectional(LSTM(units=MAX_SEQ))(input_layer)\n",
    "output_layer = Dense(class_size, activation=\"softmax\")(lstm_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:400]\n",
    "Y_train = np.array(Y_train[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('weight_farsi_dekhte.{epoch:02d}.hdf5')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "400/400 [==============================] - 0s 953us/step - loss: 0.0013\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 0s 913us/step - loss: 0.0013\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 0s 894us/step - loss: 0.0012\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 0s 886us/step - loss: 0.0012\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 0s 936us/step - loss: 0.0013\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 0s 913us/step - loss: 0.0011\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 9.8185e-04\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 9.8225e-04\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 9.2284e-04\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 8.8754e-04\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 0s 971us/step - loss: 8.5574e-04\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 0s 950us/step - loss: 8.4132e-04\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 0s 974us/step - loss: 8.0892e-04\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 0s 962us/step - loss: 7.8997e-04\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 0s 965us/step - loss: 7.5894e-04\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 7.5712e-04\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 0s 952us/step - loss: 7.3464e-04\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 0s 891us/step - loss: 7.4657e-04\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 0s 907us/step - loss: 7.0923e-04\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 0s 944us/step - loss: 6.8666e-04\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 0s 925us/step - loss: 6.6477e-04\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 0s 938us/step - loss: 6.3077e-04\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 0s 958us/step - loss: 6.0552e-04\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 0s 943us/step - loss: 6.1897e-04\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 0s 893us/step - loss: 5.8963e-04\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 0s 940us/step - loss: 5.7672e-04\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 0s 949us/step - loss: 5.5435e-04\n",
      "Epoch 29/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 6.8810e-04\n",
      "Epoch 30/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 6.2298e-04\n",
      "Epoch 31/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 5.9450e-04\n",
      "Epoch 32/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 5.1852e-04\n",
      "Epoch 33/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 4.8987e-04\n",
      "Epoch 34/50\n",
      "400/400 [==============================] - 0s 911us/step - loss: 4.9111e-04\n",
      "Epoch 35/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 4.9455e-04\n",
      "Epoch 36/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 4.6757e-04\n",
      "Epoch 37/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 4.4132e-04\n",
      "Epoch 38/50\n",
      "400/400 [==============================] - 0s 971us/step - loss: 4.5919e-04\n",
      "Epoch 39/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 4.3015e-04\n",
      "Epoch 40/50\n",
      "400/400 [==============================] - 0s 960us/step - loss: 4.1998e-04\n",
      "Epoch 41/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 4.1283e-04\n",
      "Epoch 42/50\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 4.0109e-04\n",
      "Epoch 43/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 3.8896e-04\n",
      "Epoch 44/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 3.8135e-04\n",
      "Epoch 45/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 3.6581e-04\n",
      "Epoch 46/50\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 3.6356e-04\n",
      "Epoch 47/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 3.5278e-04\n",
      "Epoch 48/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 3.4629e-04\n",
      "Epoch 49/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 3.3620e-04\n",
      "Epoch 50/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 3.3393e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d24cd978>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model\n",
    "EPOCH_SIZE = 50\n",
    "model.fit(X_train, Y_train, epochs=EPOCH_SIZE, batch_size=BATCH_SIZE, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (1, 20, 300)              0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (1, 40)                   51360     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (1, 4)                    164       \n",
      "=================================================================\n",
      "Total params: 51,524\n",
      "Trainable params: 51,524\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "input_layer = Input( batch_shape = (BATCH_SIZE, MAX_SEQ, 300))\n",
    "lstm_layer = Bidirectional(LSTM(units=MAX_SEQ))(input_layer)\n",
    "output_layer = Dense(class_size, activation=\"softmax\")(lstm_layer)\n",
    "\n",
    "dfmodel = Model(inputs=input_layer, outputs=output_layer)\n",
    "dfmodel.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam')\n",
    "dfmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "we = model.get_weights()\n",
    "dfmodel.set_weights(we)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "400/400 [==============================] - 5s 14ms/step - loss: 0.1632\n",
      "Epoch 2/20\n",
      "400/400 [==============================] - 4s 11ms/step - loss: 0.0743\n",
      "Epoch 3/20\n",
      "400/400 [==============================] - 4s 11ms/step - loss: 0.0283\n",
      "Epoch 4/20\n",
      "400/400 [==============================] - 5s 12ms/step - loss: 0.0061\n",
      "Epoch 5/20\n",
      "400/400 [==============================] - 4s 11ms/step - loss: 0.0035\n",
      "Epoch 6/20\n",
      "400/400 [==============================] - 5s 12ms/step - loss: 0.0026\n",
      "Epoch 7/20\n",
      "400/400 [==============================] - 5s 12ms/step - loss: 0.0019\n",
      "Epoch 8/20\n",
      "400/400 [==============================] - 5s 13ms/step - loss: 0.0015\n",
      "Epoch 9/20\n",
      "400/400 [==============================] - 5s 13ms/step - loss: 0.0011\n",
      "Epoch 10/20\n",
      "400/400 [==============================] - 5s 12ms/step - loss: 8.6719e-04\n",
      "Epoch 11/20\n",
      "400/400 [==============================] - 5s 12ms/step - loss: 6.6353e-04\n",
      "Epoch 12/20\n",
      "400/400 [==============================] - 5s 12ms/step - loss: 5.6430e-04\n",
      "Epoch 13/20\n",
      "400/400 [==============================] - 5s 12ms/step - loss: 5.4000e-04\n",
      "Epoch 14/20\n",
      "400/400 [==============================] - 5s 14ms/step - loss: 4.6682e-04\n",
      "Epoch 15/20\n",
      "400/400 [==============================] - 5s 13ms/step - loss: 3.6678e-04\n",
      "Epoch 16/20\n",
      "400/400 [==============================] - 5s 13ms/step - loss: 2.7769e-04\n",
      "Epoch 17/20\n",
      "400/400 [==============================] - 5s 12ms/step - loss: 2.5958e-04\n",
      "Epoch 18/20\n",
      "400/400 [==============================] - 5s 13ms/step - loss: 1.9902e-04\n",
      "Epoch 19/20\n",
      "400/400 [==============================] - 5s 12ms/step - loss: 1.7175e-04\n",
      "Epoch 20/20\n",
      "400/400 [==============================] - 5s 12ms/step - loss: 1.6040e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d3c4f588>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit model\n",
    "EPOCH_SIZE = 20\n",
    "dfmodel.fit(X_train, Y_train, epochs=EPOCH_SIZE, batch_size=BATCH_SIZE, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(sent):\n",
    "    sentence = prepareSent(sent)\n",
    "    sentence = wordToVec([sentence])[0]\n",
    "    sentence = np.reshape(sentence , (1 , 20 , 300))\n",
    "    \n",
    "    sentence = dfmodel.predict(sentence)\n",
    "    argmax = np.argmax(sentence)\n",
    "    print(sentence)\n",
    "    a = [1 if argmax == i else 0 for i in range(class_size)]\n",
    "    print(\"In class: \" , whichClass(list(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_lists = { \"cloth\" : ['شلوار' , 'کاپشن' , 'پیراهن'],\n",
    "                \"city_iran\" : ['شیراز', 'کرج', 'مشهد'],\n",
    "                \"food\" : ['کباب', 'ساندویچ', 'سوپ'],\n",
    "                \"time\" : ['امروز', 'فردا', 'دیروز']\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarity function\n",
    "def sim(dataSetI , dataSetII):\n",
    "    return 1 - spatial.distance.cosine(dataSetI, dataSetII)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Address\n",
      "https://www.google.com/maps/search/?api=1&query=%D8%A7%D8%B5%D9%81%D9%87%D8%A7%D9%86+%D9%85%DB%8C%D8%AF%D9%88%D9%86%DB%8C+%DA%86%D8%AC%D9%88%D8%B1%DB%8C+%D8%A8%D8%A7%DB%8C%D8%AF+%D8%A8%D8%B1%D9%85+%D8%B3%DB%8C+%D9%88+%D8%B3%D9%87+%D9%BE%D9%84&hl=fa\n"
     ]
    }
   ],
   "source": [
    "sent = \"میدونی چجوری باید برم سی و سه پل\"\n",
    "# sent = 'میخوام برم نظر'\n",
    "cl = classify(sent)\n",
    "sent = sent.replace(' ','+')\n",
    "print(cl)\n",
    "if cl == 'Address':\n",
    "    res = requests.get(\"https://www.google.com/maps/search/?api=1&query=اصفهان+{}&hl=fa\".format(sent))\n",
    "    print(res.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}