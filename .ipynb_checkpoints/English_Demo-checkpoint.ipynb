{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM,Dense,Input,Bidirectional\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "import pickle\n",
    "import gensim.models as gm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:red\">Preparing our Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dekhteX_train100', 'rb') as dekht:\n",
    "    X_train = pickle.load(dekht)\n",
    "with open('dekhteY_train100', 'rb') as dekhty:\n",
    "    Y_train = pickle.load(dekhty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 7)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#casting labels\n",
    "Y_train = np.array(Y_train)\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:red\">Reading our word embedding</h2>\n",
    "and preparing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "with open('/Users/mohammad/Documents/Internship-IAI/indian hotel/glove.6B.300d.txt') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        \n",
    "        coefs = [float(i) for i in values[1:]]\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "embeddings_index['<PAD>'] = [0] * 300\n",
    "embeddings_index['<UNK>'] = [1] * 300\n",
    "\n",
    "# word_embedding = gm.KeyedVectors.load_word2vec_format('/Users/mohammad/Documents/Internship-IAI/indian hotel/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "# unk_index = [1] * 300\n",
    "# pad_index = [0] * 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: red\">proccessing sentences and replacing word vectors with words</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ = 20\n",
    "for s in range(len(X_train)):\n",
    "    n = MAX_SEQ - len(X_train[s])\n",
    "    if n < 0:\n",
    "        X_train[s] = X_train[s][:MAX_SEQ]\n",
    "    else:\n",
    "        for i in range(n):\n",
    "            X_train[s].append('<PAD>')\n",
    "    for v in range(len(X_train[s])):\n",
    "        try:\n",
    "            X_train[s][v] = list(word_embedding.word_vec(X_train[s][v]))\n",
    "            \n",
    "        except:\n",
    "            X_train[s][v] = unk_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 20, 300)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#casting training set\n",
    "X_train = np.array(X_train)\n",
    "X_train.shape\n",
    "# word_embedding.word_vec(X_train[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:red\">Building model with Batch size 64</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (64, 20, 300)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (64, 40)                  51360     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (64, 7)                   287       \n",
      "=================================================================\n",
      "Total params: 51,647\n",
      "Trainable params: 51,647\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "input_layer = Input( batch_shape = (BATCH_SIZE, MAX_SEQ, 300))\n",
    "lstm_layer = Bidirectional(LSTM(units=MAX_SEQ))(input_layer)\n",
    "output_layer = Dense(7, activation=\"softmax\")(lstm_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checkpoints at the end of each epoch\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint('weight_dekhte.{epoch:02d}.hdf5')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training resize\n",
    "X_train = X_train[0:640]\n",
    "Y_train = Y_train[0:640]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load previous weights\n",
    "# model.load_weights('weight_dekhte.60.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "640/640 [==============================] - 0s 412us/step - loss: 0.0015\n",
      "Epoch 2/60\n",
      "640/640 [==============================] - 0s 387us/step - loss: 0.0015\n",
      "Epoch 3/60\n",
      "640/640 [==============================] - 0s 390us/step - loss: 0.0015\n",
      "Epoch 4/60\n",
      "640/640 [==============================] - 0s 392us/step - loss: 0.0014\n",
      "Epoch 5/60\n",
      "640/640 [==============================] - 0s 402us/step - loss: 0.0014\n",
      "Epoch 6/60\n",
      "640/640 [==============================] - 0s 391us/step - loss: 0.0014\n",
      "Epoch 7/60\n",
      "640/640 [==============================] - 0s 370us/step - loss: 0.0014\n",
      "Epoch 8/60\n",
      "640/640 [==============================] - 0s 393us/step - loss: 0.0014\n",
      "Epoch 9/60\n",
      "640/640 [==============================] - 0s 367us/step - loss: 0.0014\n",
      "Epoch 10/60\n",
      "640/640 [==============================] - 0s 387us/step - loss: 0.0014\n",
      "Epoch 11/60\n",
      "640/640 [==============================] - 0s 437us/step - loss: 0.0013\n",
      "Epoch 12/60\n",
      "640/640 [==============================] - 0s 483us/step - loss: 0.0013\n",
      "Epoch 13/60\n",
      "640/640 [==============================] - 0s 447us/step - loss: 0.0013\n",
      "Epoch 14/60\n",
      "640/640 [==============================] - 0s 571us/step - loss: 0.0013\n",
      "Epoch 15/60\n",
      "640/640 [==============================] - 0s 403us/step - loss: 0.0013\n",
      "Epoch 16/60\n",
      "640/640 [==============================] - 0s 391us/step - loss: 0.0013\n",
      "Epoch 17/60\n",
      "640/640 [==============================] - 0s 390us/step - loss: 0.0013\n",
      "Epoch 18/60\n",
      "640/640 [==============================] - 0s 390us/step - loss: 0.0012\n",
      "Epoch 19/60\n",
      "640/640 [==============================] - 0s 389us/step - loss: 0.0012\n",
      "Epoch 20/60\n",
      "640/640 [==============================] - 0s 402us/step - loss: 0.0012\n",
      "Epoch 21/60\n",
      "640/640 [==============================] - 0s 392us/step - loss: 0.0012\n",
      "Epoch 22/60\n",
      "640/640 [==============================] - 0s 439us/step - loss: 0.0012\n",
      "Epoch 23/60\n",
      "640/640 [==============================] - 0s 426us/step - loss: 0.0012\n",
      "Epoch 24/60\n",
      "640/640 [==============================] - 0s 404us/step - loss: 0.0012\n",
      "Epoch 25/60\n",
      "640/640 [==============================] - 0s 389us/step - loss: 0.0012\n",
      "Epoch 26/60\n",
      "640/640 [==============================] - 0s 389us/step - loss: 0.0011\n",
      "Epoch 27/60\n",
      "640/640 [==============================] - 0s 389us/step - loss: 0.0011\n",
      "Epoch 28/60\n",
      "640/640 [==============================] - 0s 394us/step - loss: 0.0011\n",
      "Epoch 29/60\n",
      "640/640 [==============================] - 0s 365us/step - loss: 0.0011\n",
      "Epoch 30/60\n",
      "640/640 [==============================] - 0s 388us/step - loss: 0.0011\n",
      "Epoch 31/60\n",
      "640/640 [==============================] - 0s 391us/step - loss: 0.0011\n",
      "Epoch 32/60\n",
      "640/640 [==============================] - 0s 468us/step - loss: 0.0011\n",
      "Epoch 33/60\n",
      "640/640 [==============================] - 0s 426us/step - loss: 0.0011\n",
      "Epoch 34/60\n",
      "640/640 [==============================] - 0s 644us/step - loss: 0.0010\n",
      "Epoch 35/60\n",
      "640/640 [==============================] - 0s 584us/step - loss: 0.0010\n",
      "Epoch 36/60\n",
      "640/640 [==============================] - 0s 482us/step - loss: 0.0010\n",
      "Epoch 37/60\n",
      "640/640 [==============================] - 0s 378us/step - loss: 0.0010\n",
      "Epoch 38/60\n",
      "640/640 [==============================] - 0s 443us/step - loss: 0.0010\n",
      "Epoch 39/60\n",
      "640/640 [==============================] - 0s 384us/step - loss: 9.9971e-04\n",
      "Epoch 40/60\n",
      "640/640 [==============================] - 0s 381us/step - loss: 9.8815e-04\n",
      "Epoch 41/60\n",
      "640/640 [==============================] - 0s 405us/step - loss: 9.7972e-04\n",
      "Epoch 42/60\n",
      "640/640 [==============================] - 0s 539us/step - loss: 9.6920e-04\n",
      "Epoch 43/60\n",
      "640/640 [==============================] - 0s 401us/step - loss: 9.5979e-04\n",
      "Epoch 44/60\n",
      "640/640 [==============================] - 0s 413us/step - loss: 9.5088e-04\n",
      "Epoch 45/60\n",
      "640/640 [==============================] - 0s 406us/step - loss: 9.4245e-04\n",
      "Epoch 46/60\n",
      "640/640 [==============================] - 0s 560us/step - loss: 9.3322e-04\n",
      "Epoch 47/60\n",
      "640/640 [==============================] - 0s 411us/step - loss: 9.2408e-04\n",
      "Epoch 48/60\n",
      "640/640 [==============================] - 0s 635us/step - loss: 9.1518e-04\n",
      "Epoch 49/60\n",
      "640/640 [==============================] - 0s 588us/step - loss: 9.0600e-04\n",
      "Epoch 50/60\n",
      "640/640 [==============================] - 0s 509us/step - loss: 8.9728e-04\n",
      "Epoch 51/60\n",
      "640/640 [==============================] - 0s 401us/step - loss: 8.8969e-04\n",
      "Epoch 52/60\n",
      "640/640 [==============================] - 0s 392us/step - loss: 8.8017e-04\n",
      "Epoch 53/60\n",
      "640/640 [==============================] - 0s 403us/step - loss: 8.7290e-04\n",
      "Epoch 54/60\n",
      "640/640 [==============================] - 0s 378us/step - loss: 8.6452e-04\n",
      "Epoch 55/60\n",
      "640/640 [==============================] - 0s 359us/step - loss: 8.5648e-04\n",
      "Epoch 56/60\n",
      "640/640 [==============================] - 0s 596us/step - loss: 8.4924e-04\n",
      "Epoch 57/60\n",
      "640/640 [==============================] - 0s 467us/step - loss: 8.4044e-04\n",
      "Epoch 58/60\n",
      "640/640 [==============================] - 0s 449us/step - loss: 8.3235e-04\n",
      "Epoch 59/60\n",
      "640/640 [==============================] - 0s 745us/step - loss: 8.2544e-04\n",
      "Epoch 60/60\n",
      "640/640 [==============================] - 0s 485us/step - loss: 8.1861e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f99234a8>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model\n",
    "EPOCH_SIZE = 60\n",
    "model.fit(X_train, Y_train, epochs=EPOCH_SIZE, batch_size=BATCH_SIZE, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:red\">Building model with Batch size 1</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (1, 20, 300)              0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (1, 40)                   51360     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (1, 7)                    287       \n",
      "=================================================================\n",
      "Total params: 51,647\n",
      "Trainable params: 51,647\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "input_layer = Input( batch_shape = (BATCH_SIZE, MAX_SEQ, 300))\n",
    "lstm_layer = Bidirectional(LSTM(units=MAX_SEQ))(input_layer)\n",
    "output_layer = Dense(7, activation=\"softmax\")(lstm_layer)\n",
    "\n",
    "dekhtemodel = Model(inputs=input_layer, outputs=output_layer)\n",
    "dekhtemodel.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam')\n",
    "dekhtemodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer prev model weights\n",
    "# we = model.get_weights()\n",
    "# dekhtemodel.set_weights(we)\n",
    "dekhtemodel.load_weights('last_weights.hdf5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load previous weights\n",
    "# dekhtemodel.load_weights('weight_dekhte.40.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (1, 20, 300)              0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (1, 40)                   51360     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (1, 7)                    287       \n",
      "=================================================================\n",
      "Total params: 51,647\n",
      "Trainable params: 51,647\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dekhtemodel.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam')\n",
    "dekhtemodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "640/640 [==============================] - 9s 14ms/step - loss: 0.0392\n",
      "Epoch 2/12\n",
      "640/640 [==============================] - 7s 12ms/step - loss: 0.0240\n",
      "Epoch 3/12\n",
      "640/640 [==============================] - 7s 11ms/step - loss: 0.0189\n",
      "Epoch 4/12\n",
      "640/640 [==============================] - 7s 11ms/step - loss: 0.0029\n",
      "Epoch 5/12\n",
      "640/640 [==============================] - 7s 11ms/step - loss: 0.0018\n",
      "Epoch 6/12\n",
      "640/640 [==============================] - 7s 12ms/step - loss: 0.0013\n",
      "Epoch 7/12\n",
      "640/640 [==============================] - 7s 12ms/step - loss: 0.0011\n",
      "Epoch 8/12\n",
      "640/640 [==============================] - 7s 12ms/step - loss: 7.7318e-04\n",
      "Epoch 9/12\n",
      "640/640 [==============================] - 7s 12ms/step - loss: 5.8440e-04\n",
      "Epoch 10/12\n",
      "640/640 [==============================] - 8s 12ms/step - loss: 4.3327e-04\n",
      "Epoch 11/12\n",
      "640/640 [==============================] - 8s 12ms/step - loss: 3.3648e-04\n",
      "Epoch 12/12\n",
      "640/640 [==============================] - 8s 12ms/step - loss: 2.4678e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1be69fa90>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #fit model\n",
    "EPOCH_SIZE = 12\n",
    "dekhtemodel.fit(X_train, Y_train, epochs=EPOCH_SIZE, batch_size=BATCH_SIZE, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:red\">Preparing Sentences for testing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(sentence):\n",
    "  tokenizer = TreebankWordTokenizer()\n",
    "  sent = tokenizer.tokenize(sentence)\n",
    "  for i in sent:\n",
    "    n = MAX_SEQ - len(sent)\n",
    "    if n < 0:\n",
    "      sent = sent[:MAX_SEQ]\n",
    "    else:\n",
    "        for j in range(n):\n",
    "            sent.append('<PAD>')\n",
    "  for j in range(len(sent)):\n",
    "    try:\n",
    "      sent[j] = list(word_embedding.word_vec(sent[j]))\n",
    "    except:\n",
    "      sent[j] = unk_index\n",
    "  return np.array(sent).reshape((1, 20, 300))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(sent):\n",
    "    sentence = prepare(sent)\n",
    "    sentence = dekhtemodel.predict(sentence)\n",
    "    argmax = np.argmax(sentence)\n",
    "    if argmax == 0:\n",
    "        print('AddToPlaylist')\n",
    "    elif argmax == 1:\n",
    "        print('BookRestaurant')\n",
    "    elif argmax == 2:\n",
    "#         print('GetWeather')\n",
    "        city = return_entity(sent , entity_city_iran)\n",
    "        day = return_entity(sent, entity_day)\n",
    "        print('you requested ' + city +'\\'s weather for ' + day +\"?\")\n",
    "    \n",
    "    elif argmax == 3:\n",
    "        print('PlayMusic')\n",
    "    elif argmax == 4:\n",
    "        print('RateBook')\n",
    "    elif argmax == 5:\n",
    "        print('SearchCreativeWork')\n",
    "    elif argmax == 6:\n",
    "        print('SearchScreeningEvent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:red\">Entity recognitions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarity function\n",
    "from scipy import spatial\n",
    "def sim(dataSetI , dataSetII):\n",
    "    return 1 - spatial.distance.cosine(dataSetI, dataSetII)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recognize entity\n",
    "def return_entity(sent , entity):\n",
    "    sent = sent.lower()\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    sent = tokenizer.tokenize(sent)\n",
    "    ma = 0\n",
    "    ans = \"\"\n",
    "    for i in sent: \n",
    "        try:\n",
    "            if i not in stop_words and sim(list(word_embedding.word_vec(i)) , entity) > ma:\n",
    "                ma = sim(list(word_embedding.word_vec(i)) , entity)\n",
    "                ans = i\n",
    "        except:\n",
    "            pass\n",
    "    if ma < .1:\n",
    "        return \"nothing\"\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining entities\n",
    "from nltk.corpus import stopwords\n",
    "embeddings_size = 300\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add('?')\n",
    "entity_lists = { \"cloth\" : ['t_shirt' , 'shirts' , 'jeans'],\n",
    "                \"city_iran\" : ['tehran', 'karaj', 'san_francisco'],\n",
    "                \"name_foreign\" : ['john', 'jack', 'paul'],\n",
    "                \"music_genre\" : ['pop', 'rap', 'jazz', 'rock', 'classical'],\n",
    "                \"day\" : ['tomorrow', 'today', 'yesterday', 'friday', 'sunday', 'saturdays'],\n",
    "                \"adverb\": ['sometimes', 'usually', 'never']\n",
    "                \n",
    "               }\n",
    "for ent in entity_lists:\n",
    "    sum_of_embedding = np.zeros(embeddings_size)\n",
    "    for obj in entity_lists[ent]:\n",
    "        sum_of_embedding += word_embedding.word_vec(obj)\n",
    "#         sum_of_embedding += np.array(embeddings_index[obj])\n",
    "    sum_of_embedding /= len(entity_lists[ent])\n",
    "    globals()['entity_{}'.format(ent)] = list(sum_of_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:red\">Test</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you requested sunday's weather for sunday?\n"
     ]
    }
   ],
   "source": [
    "sent1 = 'is it going to rain in texas often sunday with a R&B and some pants?'\n",
    "sent = 'is it cold tomorrow in tehran'\n",
    "sent = 'add song to playlist'\n",
    "sent = 'i want to hear something from micheal jackson'\n",
    "sent = \"how is the weather in newyork tomorrow\"\n",
    "classify(sent1)\n",
    "# print(\"city in iran: \" ,return_entity(sent , entity_city_iran))\n",
    "# print(\"adverb: \", return_entity(sent, entity_adverb))\n",
    "# print(\"time: \", return_entity(sent, entity_day))\n",
    "# print(\"genre: \", return_entity(sent, entity_music_genre))\n",
    "# print(\"clothes: \", return_entity(sent, entity_cloth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = []\n",
    "for i in stop_words:\n",
    "    try:\n",
    "        if sim(word_embedding.word_vec(i), entity_day) > .2:\n",
    "            ll.append((i , sim(word_embedding.word_vec(i), entity_day)))\n",
    "    except:\n",
    "        pass\n",
    "ll.sort(key=lambda x:x[1])ss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
